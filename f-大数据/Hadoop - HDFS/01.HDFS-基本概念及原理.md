# HDFS-基本概念及原理

NameNode 节点维护着 HDFS 文件系统中两个最重要的关系：

* HDFS 文件系统的文件目录树 （文件的数据块索引，即每个文件对应的数据块列表）
* 数据块(副本)与数据节点之间的对应关系

HDFS 的目录树、 元信息和数据块索引等信息会持久化到磁盘上，保存在 FSImage 和 EditLog中。数据块 和 数据节点的对应关系则在NameNode 启动后，由 DataNode 上报，动态建立。

## NameNode 的功能

![image-20210519142053570](https://gitee.com/minghai1024/my-image/raw/master/img/2021/20210519142053.png)

基本功能介绍

```
NameNodeHttpServer：提供Http服务
NameNodeRpcServer：RPC机制实现，名字节点与其他节点之间远程调用的实现（名字节点与客户端，名字节点之间以及数据节点与名字节点之间）。
Trash：回收站机制
JvmPauseMonitor：停顿检测
FSNamesystem：名字节点功能实现类，保存主要的数据信息
BlockManager：数据块管理
PendingReplicationBlocks：复制数据块管理
DatanodeManager：数据节点管理
DecommissionManager：节点退役管理
HeartbeatManager：心跳管理
BlockReportProcessingThread：数据块汇报管理
ReplicationMonitor：副本监视
SnapshotManager：快照管理
CacheManager：缓存管理
LeaseManager：租约管理
SafeModeMonitor：安全模式监视
NameNodeResourceMonitor：资源监视
NameNodeEditLogRoller：日志编辑
LazyPersistFileScrubber：lazyPersist文件管理
EditLogTailer：日志跟踪
StandbyCheckpointer：日志检查合并（Standby NameNode）
```



### INode



### INodeFile

NameNode中文件由 INodeFile 抽象，是 INode 的子类。INodeFIle 包含两个文件特有的属性

* header：在一个长整型变量里保存文件的副本系数和文件数据块的大小，它的高16字节存放着副本系数，低48位存放了数据块大小。

* **blocks**：文件对应的数据块，数据元素类型是 BlockInfoContiguous (2.7.0 之前为BlockInfo)，

  BlockInfo 包含

  * 数据块所属文件，即文件的 INodeFile 对象；
  * Block副本的 DataNode节点，
  * 数据块和文件、数据块和数据节点两个对应关系

### 数据块管理

INodeFile.blocks 记录了一个 HDFS 文件拥有的所有数据块。

![image-20210608180039296](https://gitee.com/minghai1024/my-image/raw/master/img/2021/20210608180039.png)

**Block**

Block 类用来唯一的标识 NameNode 中的数据块。Block 类定义了三个字段

* blockId：唯一地标识这个 Block 对象
* numBytes：数据块的大小（单位是字节）
* generationStamp：数据块的时间戳

**BlockInfoContiguous**

对 Block 的扩展说明，BlockInfoContiguous 定义了 `BlockCollection bc`字段，用来保存 block 归属于哪一个 HDFS 文件；定义了 triplets 字段保存这个 Block 的副本存储在那些 Datanode上。

**BlockInfoContiguousUnderConstruction**

HDFS  加载 fsimage 时，如果当前加载的文件处于正在构建状态，即INodeFile 中包含 FileUnderConstructionFeature 特性，则将该 INodeFile 的最后一个数据块设置为 BlockInfoContiguousUnderConstruction，表明最后一个数据块正在构建中。

**BlocksMap**

BlocksMap 管理这NameNode 上 Block 的元数据，包括当前数据块所属的HDFS文件，以及所在的 DataNode。

#### 数据块与副本

HDFS 中的数据块(block) 和副本(replica)。将 NameNode 中的数据块信息叫做数据块，将 DataNode 中保存的数据块称之为副本。

**HDFS 副本状态**

HDFS 中定义的副本的5种状态（ReplicaState）

* FINALIZED：Datanode 上的副本已经完成写操作， 不再修改。该状态的副本由FinalizedReplica类描述。
* RBW(ReplicaBeingWritten)：刚刚被创建或追加写的副本，处于写操作的数据流管道中，正在被写入，切已写入副本的内容还是可读的。该状态的副本由 ReplicaBeindWritten 类描述。
* RUR(ReplicaUnderRecovery)：租约（Lease）过期之后发生租约恢复和数据块恢复时副本所处的状态。该状态的副本使用 RelicaUnderRecovery 类描述。
* RWR(ReplicaWaitingToBeRecovered)：如果一个 Datanode 挂掉并且重新启动后，所有 RBW 状态的副本不会出现在数据流管道中，结果就是等这进行租约恢复操作。RWR 状态的副本使用 ReplicaWaitingToBeRecovered 类描述。
* TEMPORARY(ReplicaInPipeline)：Datanode 之间传输副本（例如 Cluster rebalance)时，正在传输的副本就处于 TEMPORARY 状态。和 RBW 副本不同的是，TTMPORARY 状态的副本内容是不可读的，如果 Datanode 重启，会直接删除处于 TEMPOPARY 状态的副本。该状态的副本由 ReplicaInPipeline 类描述。

**HDFS 块状态**

一个block同样有多种状态，主要有以下几种：

* **UnderConstruction**：一个block块处于正在被写入的状态。处于该状态的数据块的 长度（length）和时间戳(gs) 都是可变的，但是处于该状态的数据块对于读取操作来说是可见的。
* **UnderRecovery**：如果一个文件的最后一个数据块处于 UNDERCONSTRUCTION 状态时，客户端异常退出，该文件的租约（lease）超过 softLimit 过期，该数据块就需要进行租约恢复（Lease recovery）和数据块恢复（Block recovery）流畅释放租约关闭文件，那么正在进行租约恢复和数据块恢复流程的数据块就处于 UnderRecovery 状态。
* **Committed**：客户端在写文件时，每次请求新的数块（addBlock）或者关闭文件时，都会顺带对上一个数据块进行提交(commit)操作(上一个数据块从UNDERCONSTRUCTION状态转换成COMMITED状态)。COMMITED 状态的数据块表明客户端已经把该数据块的所有数据都发送到了 Datanode 组成的数据流管道(pipeline)中，并且已经收到下游的ACK响应，但是 Namenode 还没有收到任何一个 Datanode 汇报FINALIZED副本。
* **Complete**：数据块的 length(长度)、gs（时间戳）不再发生变化，并且 Namanode 已经收到至少一个 Datanode 报告有 FINALIZED 状态的副本（Datanode 上的副本状态发生变化时会通过 blockReceivedAndDelete() 方法向 Namenode 报告）。一个 COMPLETE 状态的数据块会在 Namenode 的内存中保存所有 FINALIZED 副本的位置。只有一个文件的所有数据块都处于Complete状态，该HDFS文件才能被关闭。

#### BlockManager

在 Namenode 中使用 BlockManager 类来管理和维护所有与数据块相关的操作。

BlockManager 中不同数据结构保存的数据块副本分以下几种状态

![image-20210609112624590](https://gitee.com/minghai1024/my-image/raw/master/img/2021/20210609112624.png)

正常副本：保存在在 BlockManager.BlocksMap 集合中的正常的数据块副本。

损坏副本：存放在 corruptReplicas 队列中的损坏的数据块副本。损坏的副本一般由 Datanode 的数据块扫描器、数据块接收器或者客户端的数据块校验过程发现。损坏状态的副本会转换为等待删除状态的副本。

多余副本：存放在 exvessReplicateMap 中数据块副本，即副本数目大于副本系数的数据块副本(一般发生在更改数据块的副本系数后)。多余状态的副本会转换为等待删除状态的副本。

等待删除副本：存放在invalidateBlocks中的数据块副本，需要由Namenode 向存放副本的 Datanode 下发删除指令。

正在复制副本：Namenode 已经生成复制命令并下发 Datanode，但 Namenode 当前并不知道副本复制操作是否成功。如果复制成功，那么正在复制状态的副本就会转换为正常状态的副本；如果复制失败，则状态重新转换至等待复制状态。

推迟操作副本：副本数目过多，但是存在 stale 副本，所以推迟处理，等待 stale 状态的 Datanode 进行块汇报。如果当前数据块不存在任何 stale 状态的副本，则状态可以转换为多余副本状态，进行删除操作。



## DataNode

DataNode 负责文件数据的存储和读写操作，HDFS 将文件数据分割成若干数据块（Block），每个 DataNode 存储一部分数据块，这样文件就分布存储在整个 HDFS 服务器集群中。

客户端进行文件操作时，先由NameNode告知客户端每个数据块在哪个节点上，然后客户端直接与DataNode守护进程进行通信，处理与数据块对应的本地文件。同时，DataNode 也会和其他 DataNode 节点进行通信，复制数据块，保证数据的冗余性。

DataNode 作为从节点，会定期向NameNode发送心跳报告。初始化时，每个DataNode将当前存储的数据块告知NameNode，后续DataNode工作过程中，DataNode节点会不断的更新，NameNode 为之提供本地修改的相关信息，并接受来自NameNode的指令，创建、移动或删除本地磁盘上数据块。

### DataNode 的逻辑结构

![image-20210128184536619](https://gitee.com/minghai1024/my-image/raw/master/img/2021/20210518182257.png)



### **DataNode 功能实现**

* 通过DataStorage以及FsDatasetImpl管理着数据节点存储上的所有数据块；

* 流式接口对客户端和其他数据节点提供读数据块、写数据块、复制数据块等功能；

* 实现InterDatanodeProtocol以及ClientDatanodeProtocol，使得数据节点可以接收来自其他数据节点以及客户端的远程rpc请求；

* BlockPoolManager对象周期性地向Namenode发送心跳、块汇报、增量块汇报以及缓存汇报，同时执行Namenode发回的command。

* 通过BlockScanner对象周期性地检查存储上的所有数据块。

* DirectoryScanner对象验证存储上数据块和内存中数据块的一致性。

> **BlockScanner**：数据块扫描器，周期性验证Datanode上存储的所有数据块的正确性，并把损坏的块报告给Namenode；
>
> Period:  21 * 24; // 3 weeks. (default)
>
> **DirectoryScanner**：主要任务定期扫描磁盘上的数据块，检查磁盘上的数据块信息是否与FsDataSetImpl中保存的数据块信息是否一致，如果不一致则对
>
> FsDatasetImpl中的信息进行更新。DirectoryScanner只会检测内存和磁盘上FINALIZED状态的数据块是否一致。
>
> Period：21600s (default)

#### 























参考资料：

* 《Hadoop 技术内幕：深入解析 Hadoop Common 和 HDFS 架构设计与实现原理》